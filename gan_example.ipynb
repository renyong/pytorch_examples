{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special thanks to \n",
    "https://www.chinahadoop.cn/course/1327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500 \n",
    "NOISE_DIM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gaussian_dist(mu, sigma): # the real data\n",
    "    temp = np.random.normal(mu, sigma, size=BATCH_SIZE)[:, np.newaxis]\n",
    "    return torch.from_numpy(temp).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.detach().storage().tolist()\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator \n",
    "G = nn.Sequential(                      \n",
    "    nn.Linear(NOISE_DIM, 128),            \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1),                  \n",
    ")\n",
    "\n",
    "# Discriminator \n",
    "D = nn.Sequential(\n",
    "    nn.Linear(1, 128),     \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1),     \n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_D = torch.optim.Adam(D.parameters(), lr=0.0001)\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: ; Real Dist ([5.041547574788332, 2.0625621607974103]),  Fake Dist ([-0.2756656590178609, 0.21883416180330068]) \n",
      "Epoch 500: ; Real Dist ([5.049333178859204, 2.0347348151536795]),  Fake Dist ([2.1628397068977354, 0.7166350538622466]) \n",
      "Epoch 1000: ; Real Dist ([5.079328663945198, 2.017614950871213]),  Fake Dist ([4.794321310520172, 1.572690531503113]) \n",
      "Epoch 1500: ; Real Dist ([4.827821336358785, 2.0167378301132515]),  Fake Dist ([6.4325278205871586, 2.0355453371253014]) \n",
      "Epoch 2000: ; Real Dist ([5.026825328994542, 2.1076865328585948]),  Fake Dist ([5.3354990940094, 1.792984728249569]) \n",
      "Epoch 2500: ; Real Dist ([4.922828404024243, 1.8385103628352337]),  Fake Dist ([4.604537794828415, 1.4728091747643883]) \n",
      "Epoch 3000: ; Real Dist ([5.222733023308217, 2.0222292308826577]),  Fake Dist ([5.374898875236512, 1.8634189113290425]) \n",
      "Epoch 3500: ; Real Dist ([4.949746106756851, 2.0439529679785253]),  Fake Dist ([5.088417758941651, 1.978777813689343]) \n",
      "Epoch 4000: ; Real Dist ([4.978446275815368, 2.031605200928159]),  Fake Dist ([5.306539332509041, 2.5440288913852385]) \n",
      "Epoch 4500: ; Real Dist ([4.954679490538314, 2.054560118351529]),  Fake Dist ([4.953037595570088, 2.7850785530082494]) \n",
      "Epoch 5000: ; Real Dist ([5.076514938250184, 1.9364513273752837]),  Fake Dist ([5.120056616336107, 2.7380364956510013]) \n",
      "Epoch 5500: ; Real Dist ([5.014135968935676, 1.9587289836816892]),  Fake Dist ([4.901957718193531, 1.9547565427441003]) \n",
      "Epoch 6000: ; Real Dist ([4.995863974872977, 1.9314996418606414]),  Fake Dist ([5.140924670696259, 1.6186553840976354]) \n",
      "Epoch 6500: ; Real Dist ([4.949397266089917, 1.8426471704069074]),  Fake Dist ([5.1352351273298265, 1.7261553853757639]) \n",
      "Epoch 7000: ; Real Dist ([5.000311264157295, 1.8916021027787224]),  Fake Dist ([4.6360327817648646, 3.0471904200906375]) \n",
      "Epoch 7500: ; Real Dist ([4.891891733661294, 1.964839855126733]),  Fake Dist ([4.770155045032501, 2.3866325602604634]) \n",
      "Epoch 8000: ; Real Dist ([5.1560638125538825, 1.8805276077287818]),  Fake Dist ([5.128326102688908, 1.5487303344831433]) \n",
      "Epoch 8500: ; Real Dist ([5.150807617932558, 2.049009367039378]),  Fake Dist ([4.938262046575546, 1.422029117684225]) \n",
      "Epoch 9000: ; Real Dist ([4.922883320808411, 1.9793602296977446]),  Fake Dist ([4.833964870765805, 1.6698369831368907]) \n",
      "Epoch 9500: ; Real Dist ([5.047794018924236, 1.9518561321169263]),  Fake Dist ([4.9397745813280345, 2.2624327297166538]) \n"
     ]
    }
   ],
   "source": [
    "for step in range(10000):\n",
    "    # train discrimintor\n",
    "    d_real_data = get_gaussian_dist(5, 2)    # real data\n",
    "    noise = torch.randn(BATCH_SIZE, NOISE_DIM)  # random noise\n",
    "    d_fake_data = G(noise)                      # fake data from G (generated from random ideas)\n",
    "\n",
    "    prob_real_decision = D(d_real_data)          # D try to increase this prob\n",
    "    prob_fake_decision = D(d_fake_data.detach()) # D try to reduce this prob\n",
    "    \n",
    "    D_loss = - torch.mean(torch.log(prob_real_decision) + torch.log(1. - prob_fake_decision))\n",
    "    opt_D.zero_grad()\n",
    "    D_loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    # train generator \n",
    "    noise = torch.randn(BATCH_SIZE, NOISE_DIM)  # random noise\n",
    "    g_fake_data = G(noise)                      # fake data from G (generated from random ideas)\n",
    "    prob_fake_decision = D(g_fake_data)         # G try to increase this prob\n",
    "    \n",
    "    G_loss = torch.mean(torch.log(1. - prob_fake_decision))\n",
    "    opt_G.zero_grad()\n",
    "    G_loss.backward()\n",
    "    opt_G.step()\n",
    "\n",
    "    if step % 500 == 0:  # plotting\n",
    "        print(\"Epoch %s: ; Real Dist (%s),  Fake Dist (%s) \" %\n",
    "                  (step, stats(extract(d_real_data)), stats(extract(g_fake_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Plotting the generated distribution...\")\n",
    "values = extract(g_fake_data)\n",
    "plt.hist(values, bins=50,color=\"red\")\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "#plt.title('Histogram of Generated Distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Plotting the generated distribution...\")\n",
    "values = extract(d_real_data)\n",
    "plt.hist(values, bins=50)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Real Distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
