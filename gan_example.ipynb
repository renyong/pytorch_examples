{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special thanks to \n",
    "https://www.chinahadoop.cn/course/1327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500 \n",
    "NOISE_DIM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gaussian_dist(mu, sigma): # the real data\n",
    "    temp = np.random.normal(mu, sigma, size=BATCH_SIZE)[:, np.newaxis]\n",
    "    return torch.from_numpy(temp).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.detach().storage().tolist()\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator \n",
    "G = nn.Sequential(                      \n",
    "    nn.Linear(NOISE_DIM, 128),            \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1),                  \n",
    ")\n",
    "\n",
    "# Discriminator \n",
    "D = nn.Sequential(\n",
    "    nn.Linear(1, 128),     \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1),     \n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_D = torch.optim.Adam(D.parameters(), lr=0.0001)\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: ; Real Dist ([5.067422164037824, 2.0268136991888213]),  Fake Dist ([-0.13762627686187626, 0.12559447968408524]) \n",
      "Epoch 500: ; Real Dist ([4.95735705780983, 2.00384641364993]),  Fake Dist ([3.0464577887058257, 0.880591239461629]) \n",
      "Epoch 1000: ; Real Dist ([4.990398664072156, 2.0437309877125798]),  Fake Dist ([5.893177792072296, 1.576236947167336]) \n",
      "Epoch 1500: ; Real Dist ([5.097402470998466, 1.97503666138329]),  Fake Dist ([6.415912767410278, 1.7493719966267285]) \n",
      "Epoch 2000: ; Real Dist ([4.977614680558443, 2.073433243487078]),  Fake Dist ([4.587025060653686, 1.3611078646869337]) \n",
      "Epoch 2500: ; Real Dist ([5.020027194902301, 1.9687778726397451]),  Fake Dist ([4.95946099948883, 1.519033190055754]) \n",
      "Epoch 3000: ; Real Dist ([5.2128319461643695, 1.844861419961821]),  Fake Dist ([5.041665683746338, 1.713292325384186]) \n",
      "Epoch 3500: ; Real Dist ([5.0327643441818655, 1.9598375931970633]),  Fake Dist ([5.118369703292847, 2.227701643320257]) \n",
      "Epoch 4000: ; Real Dist ([4.920529795616865, 1.9799972673853248]),  Fake Dist ([4.904139602899551, 2.3752073605875936]) \n",
      "Epoch 4500: ; Real Dist ([5.046461019977928, 1.922220765946229]),  Fake Dist ([4.984212647527456, 2.6319919463228363]) \n",
      "Epoch 5000: ; Real Dist ([5.150404705572873, 1.9741435233214635]),  Fake Dist ([4.8233003027141095, 2.9439469405402416]) \n",
      "Epoch 5500: ; Real Dist ([5.021140588074923, 2.068732944699686]),  Fake Dist ([5.098145845770836, 1.8691478651356102]) \n",
      "Epoch 6000: ; Real Dist ([5.013232044488191, 1.9628589875269795]),  Fake Dist ([5.19002046251297, 1.4512334804912892]) \n",
      "Epoch 6500: ; Real Dist ([5.060087473452091, 2.076947344341394]),  Fake Dist ([5.106041074752808, 1.3944873793610268]) \n",
      "Epoch 7000: ; Real Dist ([4.931617967510596, 2.073002501279365]),  Fake Dist ([5.077078555226326, 1.9352538146816993]) \n",
      "Epoch 7500: ; Real Dist ([5.094101687759161, 2.069433035892949]),  Fake Dist ([4.88028355383873, 2.2792741279274367]) \n",
      "Epoch 8000: ; Real Dist ([5.082061994671822, 2.113517662701373]),  Fake Dist ([4.9636827833652495, 1.6560751275242438]) \n",
      "Epoch 8500: ; Real Dist ([5.058128055602312, 2.0922896326197478]),  Fake Dist ([5.065963567763567, 2.0594168195373137]) \n",
      "Epoch 9000: ; Real Dist ([5.0942551980018616, 1.957046330495769]),  Fake Dist ([5.131147915720939, 2.1558844951044187]) \n",
      "Epoch 9500: ; Real Dist ([5.1557483087778095, 1.982737757267349]),  Fake Dist ([5.153296624988317, 1.9099874607481684]) \n"
     ]
    }
   ],
   "source": [
    "for step in range(10000):\n",
    "    # train discrimintor\n",
    "    d_real_data = get_gaussian_dist(5, 2)    # real data\n",
    "    noise = torch.randn(BATCH_SIZE, NOISE_DIM)  # random noise\n",
    "    d_fake_data = G(noise)                      # fake data from G (generated from random ideas)\n",
    "\n",
    "    prob_real_decision = D(d_real_data)          # D try to increase this prob\n",
    "    prob_fake_decision = D(d_fake_data.detach()) # D try to reduce this prob\n",
    "    \n",
    "    D_loss = - torch.mean(torch.log(prob_real_decision) + torch.log(1. - prob_fake_decision))\n",
    "    opt_D.zero_grad()\n",
    "    D_loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    # train generator \n",
    "    noise = torch.randn(BATCH_SIZE, NOISE_DIM)  # random noise\n",
    "    g_fake_data = G(noise)                      # fake data from G (generated from random ideas)\n",
    "    prob_fake_decision = D(g_fake_data)         # G try to increase this prob\n",
    "    \n",
    "    G_loss = torch.mean(torch.log(1. - prob_fake_decision))\n",
    "    opt_G.zero_grad()\n",
    "    G_loss.backward()\n",
    "    opt_G.step()\n",
    "\n",
    "    if step % 500 == 0:  # plotting\n",
    "        print(\"Epoch %s: ; Real Dist (%s),  Fake Dist (%s) \" %\n",
    "                  (step, stats(extract(d_real_data)), stats(extract(g_fake_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting the generated distribution...\")\n",
    "values = extract(g_fake_data)\n",
    "plt.hist(values, bins=50,color=\"red\")\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Generated Distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Plotting the generated distribution...\")\n",
    "values = extract(d_real_data)\n",
    "plt.hist(values, bins=50)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Real Distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
